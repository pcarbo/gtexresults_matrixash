---
title: "standarderrortwo"
output: pdf_document
---


The aim of this document is to investigate the correlation of standard error and sample size, and to show how the presence of small sample sizes and large standard errors in biologically 'unique' tissues drives incompatibilities between the fold-size sharing heatmap and significance sharing heatmap.

```{r echo=FALSE,message=FALSE}
library('knitr')

knitr::opts_chunk$set(cache=TRUE)
opts_chunk$set(fig.path = "/Users/sarahurbut/Dropbox/PaperEdits/Paper/Figures/") 

data=read.csv("../SampleSizeInvestigation/ExprSampleSize.csv.gz",header = T)
rownames(data)=data[,1]
expr.data=data[,-1]
maxz=read.table("../Data/maxz.txt")
qtl.names=sapply(1:length(rownames(maxz)),function(x){unlist(strsplit(rownames(maxz)[x], "[_]"))[[1]]})
expr.sort=expr.data[rownames(expr.data)%in%qtl.names,]


a=match(qtl.names,rownames(expr.sort))###in order to make sure the gene names are the same in both


expr.sort=expr.sort[a,]



missing.tissues=c(7,8,19,20,24,25,31,34,37)
exp.sort=expr.sort[,-missing.tissues]
colnames(exp.sort)=colnames(maxz)
standard.error=read.table("../Data/standard.error.txt")
colnames(standard.error)=colnames(maxz)


maxz=read.table("../../Dropbox/jul3/maxz.txt")
maxbeta=read.table("../Data/maxbetahats.txt")
tissue.names=colnames(maxz)
standard.error.from.z=as.matrix(maxbeta/maxz)##since we use the maxz to compute this model, we should use this standard error
pm.mash=as.matrix(read.table("../../Dropbox//Aug12/Aug13withEDposterior.means.txt")[,-1])
#pm.mash.omega=as.matrix(read.table("withzeroomega2posterior.means.txt")[,-1])
pm.mash.beta=pm.mash*standard.error.from.z

```

Look at the ordering of Sample Size and see how it is almost identical to that of standard error, though no sample sizes differ by more than about 4 fold. 

```{r, echo=FALSE}
size=apply(exp.sort,2,unique)
median.standard.error=apply(standard.error,2,median)
```



Now we look at the median posterior variances:
```{r effectivesamplesizemarvarplot2}
#marginal.var=read.table("../../Dropbox/Aug12/Aug13withEDmarginal.var.txt")[,-1]
marginal.var=read.table("../Results_Data/withzeromarginal.var.txt")[,-1]
median.mar.var=apply(marginal.var,2,median)
barplot(sort(1/median.mar.var,decreasing=F),cex.names=0.5,main="Effective Sample Size: 1/MedianMarginalVariance",names=colnames(maxz)[order(1/median.mar.var,decreasing=F)],las=2)
```

Now let's plot effective sample size. Recall:

$$n_{jeff}=\frac{s_{j}^2}{\tilde{s_{j}^2}}$$

```{r effectivesampleplotsagain}
original.var=as.matrix(standard.error.from.z)^2
#original.var=(standard.error.from.z/standard.error.from.z)^2
size=as.matrix(exp.sort)
post.var=as.matrix(marginal.var)*standard.error.from.z^2
njeffective=size*original.var/post.var

gtex.colors=read.table('../Data/GTExColors.txt', sep = '\t', comment.char = '')[-missing.tissues,2]
missing.tissues=c(7,8,19,20,24,25,31,34,37)

##ask why some of the origianl variancres are smaller than posterior variances, even though calculations are right (e.g. 16012, 44)
###15093  44
increase=njeffective/size


barplot(sort(apply(increase,2,median),decreasing=F),las=2,cex.names=0.4)
title("Median(Nj_effective/Nj_original)")



barplot(sort(apply(njeffective,2,median),decreasing=F),cex.names=0.4,las=2)
title("MedianNj_effective")

barplot(sort(apply(increase,2,median),decreasing=F),las=2,col=as.character(gtex.colors[order(apply(increase,2,median),decreasing=F)]))
title("Median(Nj_effective/Nj_original)")

barplot(sort(apply(njeffective,2,median),decreasing=F),cex.names=0.4,las=2,col=as.character(gtex.colors[order(apply(njeffective,2,median),decreasing=F)]))
title("MedianNj_effective")

```


Let's plot again with order by original sample size:
```{r reorder-again}

par(mfrow=c(1,2))
samplesize=apply(size,2,function(x){unique(x)})
sampleorder=order(samplesize,decreasing = T)
median.nj.effective=apply(njeffective,2,median)
median.nj.increase=apply(increase,2,median)

par(mar=c(5.1,8,4.1,0.1))
barplot(median.nj.effective[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T)
title("MedianNj_effective",cex.main=0.8)
par(mar=c(5.1,2,4.1,6))
barplot(median.nj.increase[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T,names="",xlim=c(16,0))
title("Median(Nj_effective/Nj_original)",cex.main=0.8)



par(mfrow=c(1,2))
samplesize=apply(size,2,function(x){unique(x)})
sampleorder=order(samplesize,decreasing = T)
median.nj.effective=apply(njeffective,2,median)
median.nj.increase=apply(increase,2,median)


par(mar=c(5.1,8,1.1,0.1))
barplot(samplesize[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T,xlim=c(0,2000))
title("Sample Size",cex.main=0.8)

par(mar=c(5.1,2,1.1,6))
barplot(median.nj.effective[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T,names="",xlim=c(0,2000))

title("Effective Sample Size",cex.main=0.8)
```
WE could also do back to back


```{r backtobacksamplesize}
par(mfrow=c(1,2))
samplesize=apply(size,2,function(x){unique(x)})
sampleorder=order(samplesize,decreasing = T)
median.nj.effective=apply(njeffective,2,median)
median.nj.increase=apply(increase,2,median)


par(mar=c(5.1,8,1.1,0.1))
barplot(samplesize[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T,xlim=c(2000,0))
title("Sample Size",cex.main=0.8)

par(mar=c(5.1,2,1.1,6))
barplot(median.nj.effective[sampleorder],cex.names=0.4,las=2,col=as.character(gtex.colors[sampleorder]),horiz = T,names="",xlim=c(0,2000))

title("Effective Sample Size",cex.main=0.8)


```

To figure out average increase across tissues:

```{r}
mean(apply(increase,2,median))
```
